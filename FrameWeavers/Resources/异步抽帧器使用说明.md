# 异步视频抽帧器使用说明

## 📋 目录
- [概述](#概述)
- [核心特性](#核心特性)
- [快速开始](#快速开始)
- [详细使用方法](#详细使用方法)
- [性能优化](#性能优化)
- [API参考](#API参考)
- [常见问题](#常见问题)

## 概述

`AsyncFrameExtractor` 是一个高性能的异步视频抽帧器，基于原有的 `OptimizedFrameExtractor` 改造而成。它支持多文件并行处理、设备性能自适应调整、实时进度监控和智能资源管理。

### 🆚 与原版本对比

| 特性 | 原始版本 | 异步版本 | 改进效果 |
|------|----------|----------|----------|
| 处理方式 | 同步串行 | 异步并行 | **3-5倍性能提升** |
| 多文件处理 | 逐个处理 | 批量并行 | **显著减少总时间** |
| 资源利用 | 单线程 | 多线程池 | **充分利用CPU** |
| 内存管理 | 基础管理 | 智能监控 | **更稳定运行** |
| 进度监控 | 无 | 实时回调 | **更好的用户体验** |
| 设备适配 | 固定配置 | 性能检测 | **自动优化配置** |

## 核心特性

### 🚀 异步并行处理
- **多文件并行**: 同时处理多个视频/图片文件
- **批处理优化**: 根据设备性能智能分批处理
- **线程池管理**: 高效的线程资源利用
- **非阻塞操作**: 不会阻塞主线程

### 🔍 设备性能检测
- **自动检测**: CPU核心数、内存大小、系统负载
- **性能分级**: High/Medium/Low/Minimal 四个等级
- **动态调整**: 根据设备性能自动调整并发参数
- **资源监控**: 实时监控内存使用和系统状态

### 📊 实时进度监控
- **进度回调**: 支持自定义进度回调函数
- **详细信息**: 总体进度、当前文件、剩余时间
- **状态更新**: 实时更新处理状态
- **异步通知**: 非阻塞的进度通知机制

### 🛡️ 智能资源管理
- **内存监控**: 自动检测内存使用率
- **垃圾回收**: 定期清理内存资源
- **信号量控制**: 限制并发数防止资源耗尽
- **优雅清理**: 异步上下文管理器支持

## 快速开始

### 安装依赖

```bash
pip install opencv-python numpy psutil asyncio
```

### 基础使用示例

```python
import asyncio
from async_frame_extractor import AsyncFrameExtractor

async def main():
    # 创建异步抽帧器
    async with AsyncFrameExtractor(output_dir="output_frames") as extractor:
        
        # 处理单个视频
        result = await extractor.process_and_format_async(
            input_paths=["video.mp4"],
            device_id="my_device_001",
            quality=90,
            max_resolution=(1920, 1080)
        )
        
        if result['success']:
            print(f"✅ 成功提取 {len(result['base_frame_paths'])} 帧")
        else:
            print(f"❌ 处理失败: {result['error']}")

# 运行异步函数
asyncio.run(main())
```

### 多文件并行处理

```python
import asyncio
from async_frame_extractor import AsyncFrameExtractor

async def progress_callback(progress_data):
    """进度回调函数"""
    print(f"进度: {progress_data['overall_progress']:.1f}% | "
          f"当前: {progress_data['current_file']} | "
          f"剩余: {progress_data['estimated_remaining']:.1f}s")

async def main():
    # 多文件并行处理
    async with AsyncFrameExtractor() as extractor:
        
        files = ["video1.mp4", "video2.mp4", "image1.jpg", "video3.avi"]
        
        result = await extractor.process_and_format_async(
            input_paths=files,
            device_id="batch_device_001",
            quality=85,
            scene_sensitivity='high',
            max_base_frames=100,
            progress_callback=progress_callback  # 实时进度监控
        )
        
        print(f"处理完成: {result['processing_summary']}")

asyncio.run(main())
```

## 详细使用方法

### 1. 初始化配置

```python
extractor = AsyncFrameExtractor(
    output_dir="async_frames",           # 输出目录
    max_file_size_mb=500,               # 最大文件大小(MB)
    auto_detect_performance=True        # 自动检测设备性能
)
```

### 2. 设备性能检测

```python
# 获取设备性能信息
profile = extractor.performance_profile
print(f"性能等级: {profile['performance_level']}")
print(f"CPU核心: {profile['cpu_cores_physical']}")
print(f"内存: {profile['memory_total_gb']} GB")
print(f"推荐并发: {profile['max_workers']}")
```

### 3. 处理参数配置

```python
result = await extractor.process_and_format_async(
    input_paths=files,
    device_id="my_device",                    # 设备ID
    task_id=None,                            # 任务ID(自动生成)
    save_json=True,                          # 保存JSON结果
    
    # 抽帧参数
    quality=90,                              # JPEG质量(1-100)
    max_resolution=(1920, 1080),             # 最大分辨率
    sharpness_threshold=100.0,               # 清晰度阈值
    similarity_threshold=15.0,               # 相似度阈值
    scene_sensitivity='high',                # 场景变化敏感度
    max_base_frames=80,                      # 最大提取帧数
    
    # 进度回调
    progress_callback=my_progress_callback
)
```

### 4. 自定义进度回调

```python
async def my_progress_callback(progress_data):
    """自定义进度回调函数"""
    data = progress_data
    
    # 控制台输出
    print(f"\r📊 [{data['overall_progress']:6.1f}%] "
          f"{data['completed_files']}/{data['total_files']} | "
          f"{data['current_file'][:30]:30s} "
          f"({data['current_file_progress']:5.1f}%)", 
          end="", flush=True)
    
    # 可以在这里添加其他逻辑：
    # - 更新GUI进度条
    # - 发送进度到Web前端
    # - 记录日志
    # - 检查取消状态等
```

## 性能优化

### 设备性能等级说明

| 性能等级 | CPU核心 | 内存 | 最大工作线程 | 批处理大小 | 适用场景 |
|----------|---------|------|--------------|------------|----------|
| **High** | ≥8核 | ≥16GB | 16 | 8 | 服务器、高端工作站 |
| **Medium** | 4-7核 | 8-15GB | 8 | 4 | 普通台式机、笔记本 |
| **Low** | 2-3核 | 4-7GB | 4 | 2 | 入门级设备 |
| **Minimal** | <2核 | <4GB | 2 | 1 | 低端设备、虚拟机 |

### 性能调优建议

#### 1. 针对不同场景的参数建议

```python
# 🚀 高性能场景 - 服务器批处理
config_high_performance = {
    'quality': 85,
    'max_resolution': (1920, 1080),
    'scene_sensitivity': 'medium',
    'max_base_frames': 150
}

# 🎯 平衡场景 - 普通桌面处理
config_balanced = {
    'quality': 90,
    'max_resolution': (1280, 720),
    'scene_sensitivity': 'high',
    'max_base_frames': 80
}

# 💾 低资源场景 - 限制内存使用
config_low_resource = {
    'quality': 75,
    'max_resolution': (800, 600),
    'scene_sensitivity': 'low',
    'max_base_frames': 50
}
```

#### 2. 内存优化策略

```python
# 处理大量文件时分批处理
large_files = get_large_file_list()  # 假设有很多文件

# 分批处理，避免内存耗尽
batch_size = 10
for i in range(0, len(large_files), batch_size):
    batch = large_files[i:i + batch_size]
    
    result = await extractor.process_and_format_async(
        input_paths=batch,
        device_id=f"batch_{i//batch_size}",
        **config_balanced
    )
    
    # 处理结果...
    await asyncio.sleep(1)  # 短暂休息，让系统回收资源
```

#### 3. 错误处理和重试机制

```python
import asyncio
from typing import List

async def robust_process_with_retry(extractor, files: List[str], max_retries: int = 3):
    """带重试机制的健壮处理"""
    
    for attempt in range(max_retries):
        try:
            result = await extractor.process_and_format_async(
                input_paths=files,
                device_id=f"retry_attempt_{attempt+1}",
                quality=85
            )
            
            if result['success']:
                return result
            else:
                print(f"第 {attempt+1} 次尝试失败: {result.get('error')}")
                
        except Exception as e:
            print(f"第 {attempt+1} 次尝试异常: {str(e)}")
            
        if attempt < max_retries - 1:
            wait_time = 2 ** attempt  # 指数退避
            print(f"等待 {wait_time} 秒后重试...")
            await asyncio.sleep(wait_time)
    
    return {'success': False, 'error': '达到最大重试次数'}
```

## API参考

### AsyncFrameExtractor 类

#### 构造函数
```python
AsyncFrameExtractor(
    output_dir: str = "async_frames",
    max_file_size_mb: int = 500,
    auto_detect_performance: bool = True
)
```

#### 主要方法

##### process_and_format_async()
```python
async def process_and_format_async(
    self,
    input_paths: List[str],
    device_id: str = None,
    task_id: str = None,
    save_json: bool = True,
    progress_callback: Callable = None,
    **kwargs
) -> Dict[str, any]
```

**参数说明:**
- `input_paths`: 输入文件路径列表
- `device_id`: 设备标识符
- `task_id`: 任务ID（如果为None则自动生成）
- `save_json`: 是否保存JSON结果文件
- `progress_callback`: 进度回调函数
- `**kwargs`: 其他处理参数

**返回格式:**
```python
{
    'success': bool,                    # 是否成功
    'device_id': str,                   # 设备ID
    'task_id': str,                     # 任务ID
    'base_frame_paths': List[Dict],     # 提取的帧信息列表
    'processing_summary': {             # 处理总结
        'total_input_files': int,
        'success_files': int,
        'failed_files': int,
        'final_frame_count': int,
        'processing_time_seconds': float,
        'performance_profile': Dict
    },
    'storage_info': {                   # 存储信息
        'task_output_directory': str,
        'total_size_mb': float,
        'frame_format': str,
        'json_result_path': str
    },
    'metadata': {                       # 元数据
        'extraction_timestamp': str,
        'extractor_version': str,
        'async_processing': bool,
        'parallel_batches': bool
    }
}
```

### 进度回调函数格式

```python
async def progress_callback(progress_data: Dict[str, any]):
    """
    progress_data 包含以下字段:
    - total_files: int - 总文件数
    - completed_files: int - 已完成文件数
    - current_file: str - 当前处理文件名
    - current_file_progress: float - 当前文件进度(0-100)
    - overall_progress: float - 总体进度(0-100)
    - elapsed_time: float - 已消耗时间(秒)
    - estimated_remaining: float - 预计剩余时间(秒)
    """
    pass
```

## 常见问题

### Q: 如何选择合适的并发参数？

**A:** 系统会自动检测设备性能并选择最佳参数。但你也可以手动调整：

```python
# 如果内存不足，降低批处理大小
extractor.performance_profile['concurrency_config']['batch_size'] = 2

# 如果CPU利用率低，增加工作线程
extractor.performance_profile['concurrency_config']['max_workers'] = 8
```

### Q: 处理大文件时内存不足怎么办？

**A:** 采用以下策略：

1. **降低分辨率**: `max_resolution=(800, 600)`
2. **减少质量**: `quality=70`
3. **减少并发**: 手动设置更小的批处理大小
4. **分批处理**: 将大量文件分成小批次处理

```python
# 低内存模式
low_memory_config = {
    'quality': 70,
    'max_resolution': (800, 600),
    'max_base_frames': 30
}

# 手动设置低并发
extractor.performance_profile['concurrency_config']['batch_size'] = 1
extractor.performance_profile['concurrency_config']['max_workers'] = 2
```

### Q: 如何监控处理进度和状态？

**A:** 使用进度回调函数：

```python
async def detailed_progress_callback(progress_data):
    # 计算速度
    if progress_data['elapsed_time'] > 0:
        files_per_second = progress_data['completed_files'] / progress_data['elapsed_time']
        print(f"处理速度: {files_per_second:.2f} 文件/秒")
    
    # 内存监控
    import psutil
    memory_percent = psutil.virtual_memory().percent
    print(f"内存使用: {memory_percent:.1f}%")
    
    # 磁盘空间检查
    disk_free = psutil.disk_usage('.').free / (1024**3)
    print(f"剩余空间: {disk_free:.1f} GB")
```

### Q: 处理失败的文件如何重试？

**A:** 可以从结果中获取失败信息并单独重试：

```python
result = await extractor.process_and_format_async(files)

if result['processing_summary']['failed_files'] > 0:
    # 查看详细错误（需要查看日志）
    # 或者实现更详细的错误追踪机制
    print(f"有 {result['processing_summary']['failed_files']} 个文件处理失败")
    
    # 可以尝试用更保守的参数重试
    retry_config = {
        'quality': 70,
        'max_resolution': (640, 480),
        'scene_sensitivity': 'low'
    }
```

### Q: 如何与Web应用集成？

**A:** 异步特性使其很容易与Web框架集成：

```python
# FastAPI 示例
from fastapi import FastAPI, BackgroundTasks
import asyncio

app = FastAPI()

@app.post("/process_videos/")
async def process_videos(files: List[str], background_tasks: BackgroundTasks):
    
    async def background_process():
        async with AsyncFrameExtractor() as extractor:
            result = await extractor.process_and_format_async(
                input_paths=files,
                device_id="web_api_001"
            )
            # 保存结果到数据库或缓存
            save_result_to_db(result)
    
    background_tasks.add_task(background_process)
    return {"message": "Processing started", "status": "queued"}
```

### Q: 支持哪些文件格式？

**A:** 支持常见的视频和图片格式：

- **视频格式**: .mp4, .avi, .mov, .mkv, .wmv, .flv, .webm, .m4v
- **图片格式**: .jpg, .jpeg, .png, .bmp, .tiff, .tif, .webp

### Q: 如何自定义输出格式？

**A:** 当前输出为JPEG格式，可以通过修改保存参数调整：

```python
# 在 _extract_frames_sync 方法中可以看到:
jpeg_params = [cv2.IMWRITE_JPEG_QUALITY, quality]

# 可以扩展支持其他格式，比如PNG:
# png_params = [cv2.IMWRITE_PNG_COMPRESSION, 9]
```

---

## 📞 技术支持

如果您在使用过程中遇到问题，请：

1. 查看控制台日志输出
2. 检查文件格式和大小是否符合要求
3. 确认设备资源充足
4. 尝试降低处理参数

**享受高效的异步并行抽帧体验！** 🚀