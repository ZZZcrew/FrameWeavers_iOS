import cv2
import os
import numpy as np
import asyncio
import psutil
import threading
import concurrent.futures
from typing import List, Dict, Optional, Tuple, Union, Callable, Awaitable
import time
from datetime import datetime
import logging
import json
from collections import deque
import gc
import weakref

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ç¡®ä¿OpenCVä½¿ç”¨CPUåç«¯ï¼Œä¼˜åŒ–CPUæ€§èƒ½
cv2.setUseOptimized(True)
cv2.setNumThreads(0)

# æ— å¤´ç¯å¢ƒé…ç½®
os.environ['OPENCV_IO_ENABLE_OPENEXR'] = '0'
os.environ['OPENCV_IO_ENABLE_JASPER'] = '0'

# =============================================================================
# è®¾å¤‡æ€§èƒ½æ£€æµ‹æ¨¡å—
# =============================================================================

class DevicePerformanceDetector:
    """è®¾å¤‡æ€§èƒ½æ£€æµ‹å™¨"""
    
    def __init__(self):
        self.cpu_count = psutil.cpu_count(logical=False)  # ç‰©ç†CPUæ ¸å¿ƒæ•°
        self.logical_cpu_count = psutil.cpu_count(logical=True)  # é€»è¾‘CPUæ ¸å¿ƒæ•°
        self.total_memory = psutil.virtual_memory().total
        self.available_memory = psutil.virtual_memory().available
        
    def get_performance_profile(self) -> Dict[str, any]:
        """è·å–è®¾å¤‡æ€§èƒ½æ¡£æ¡ˆ"""
        try:
            # CPUä¿¡æ¯
            cpu_percent = psutil.cpu_percent(interval=1)
            memory_info = psutil.virtual_memory()
            disk_info = psutil.disk_usage('/')
            
            # åŸºäºç¡¬ä»¶é…ç½®è®¡ç®—æ€§èƒ½ç­‰çº§
            performance_level = self._calculate_performance_level()
            
            # æ ¹æ®æ€§èƒ½ç­‰çº§è°ƒæ•´å¹¶å‘å‚æ•°
            concurrency_config = self._get_concurrency_config(performance_level)
            
            profile = {
                'cpu_cores_physical': self.cpu_count,
                'cpu_cores_logical': self.logical_cpu_count,
                'cpu_usage_percent': cpu_percent,
                'memory_total_gb': round(self.total_memory / (1024**3), 2),
                'memory_available_gb': round(memory_info.available / (1024**3), 2),
                'memory_usage_percent': memory_info.percent,
                'disk_free_gb': round(disk_info.free / (1024**3), 2),
                'performance_level': performance_level,
                'concurrency_config': concurrency_config,
                'recommended_batch_size': concurrency_config['batch_size'],
                'max_workers': concurrency_config['max_workers']
            }
            
            logger.info(f"ğŸ” è®¾å¤‡æ€§èƒ½æ£€æµ‹å®Œæˆ - æ€§èƒ½ç­‰çº§: {performance_level}")
            return profile
            
        except Exception as e:
            logger.warning(f"æ€§èƒ½æ£€æµ‹å¤±è´¥: {e}, ä½¿ç”¨é»˜è®¤é…ç½®")
            return self._get_default_profile()
    
    def _calculate_performance_level(self) -> str:
        """è®¡ç®—æ€§èƒ½ç­‰çº§"""
        memory_gb = self.total_memory / (1024**3)
        
        # æ ¹æ®CPUæ ¸å¿ƒæ•°å’Œå†…å­˜åˆ¤æ–­æ€§èƒ½ç­‰çº§
        if self.cpu_count >= 8 and memory_gb >= 16:
            return "high"
        elif self.cpu_count >= 4 and memory_gb >= 8:
            return "medium"
        elif self.cpu_count >= 2 and memory_gb >= 4:
            return "low"
        else:
            return "minimal"
    
    def _get_concurrency_config(self, performance_level: str) -> Dict[str, int]:
        """æ ¹æ®æ€§èƒ½ç­‰çº§è·å–å¹¶å‘é…ç½®"""
        configs = {
            "high": {
                "max_workers": min(self.cpu_count * 2, 16),
                "batch_size": 8,
                "memory_buffer_mb": 2048,
                "io_workers": 4
            },
            "medium": {
                "max_workers": min(self.cpu_count + 2, 8),
                "batch_size": 4,
                "memory_buffer_mb": 1024,
                "io_workers": 2
            },
            "low": {
                "max_workers": min(self.cpu_count, 4),
                "batch_size": 2,
                "memory_buffer_mb": 512,
                "io_workers": 1
            },
            "minimal": {
                "max_workers": 2,
                "batch_size": 1,
                "memory_buffer_mb": 256,
                "io_workers": 1
            }
        }
        return configs.get(performance_level, configs["low"])
    
    def _get_default_profile(self) -> Dict[str, any]:
        """è·å–é»˜è®¤æ€§èƒ½æ¡£æ¡ˆ"""
        return {
            'cpu_cores_physical': 4,
            'cpu_cores_logical': 8,
            'cpu_usage_percent': 50.0,
            'memory_total_gb': 8.0,
            'memory_available_gb': 4.0,
            'memory_usage_percent': 50.0,
            'disk_free_gb': 10.0,
            'performance_level': 'medium',
            'concurrency_config': {
                'max_workers': 4,
                'batch_size': 2,
                'memory_buffer_mb': 512,
                'io_workers': 1
            },
            'recommended_batch_size': 2,
            'max_workers': 4
        }

# =============================================================================
# å¼‚æ­¥æŠ½å¸§å™¨é…ç½®
# =============================================================================

class AsyncFrameExtractorConfig:
    """å¼‚æ­¥æŠ½å¸§å™¨é…ç½®å¸¸é‡"""
    
    # ç»§æ‰¿æ‰€æœ‰åŸå§‹é…ç½®
    SUPPORTED_VIDEO_FORMATS = {'.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm', '.m4v'}
    SUPPORTED_IMAGE_FORMATS = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.webp'}
    
    DEFAULT_OUTPUT_DIR = "async_frames"
    DEFAULT_MAX_FILE_SIZE_MB = 500
    DEFAULT_QUALITY = 95
    DEFAULT_SHARPNESS_THRESHOLD = 100.0
    DEFAULT_SIMILARITY_THRESHOLD = 15.0
    DEFAULT_MAX_BASE_FRAMES = 80
    DEFAULT_SCENE_SENSITIVITY = 'high'
    
    # å¼‚æ­¥å¤„ç†é…ç½®
    DEFAULT_TIMEOUT_SECONDS = 3600  # 1å°æ—¶è¶…æ—¶
    PROGRESS_UPDATE_INTERVAL = 0.5  # è¿›åº¦æ›´æ–°é—´éš”ï¼ˆç§’ï¼‰
    MEMORY_CHECK_INTERVAL = 100     # æ¯å¤„ç†100å¸§æ£€æŸ¥å†…å­˜
    MAX_MEMORY_USAGE_PERCENT = 80   # æœ€å¤§å†…å­˜ä½¿ç”¨ç‡
    
    # æ—¶é—´é—´éš”é…ç½®ï¼ˆç§’ï¼‰
    INTERVAL_ULTRA_SHORT = 0.2
    INTERVAL_SHORT = 0.5
    INTERVAL_MEDIUM_SHORT = 0.8
    INTERVAL_MEDIUM = 1.0
    INTERVAL_LONG = 1.5
    INTERVAL_VERY_LONG = 2.0
    INTERVAL_EXTRA_LONG = 2.5
    INTERVAL_HOUR = 3.0
    INTERVAL_SUPER_LONG = 4.0
    
    # æ—¶é•¿åˆ†ç±»é˜ˆå€¼ï¼ˆç§’ï¼‰
    DURATION_ULTRA_SHORT = 3
    DURATION_SHORT = 10
    DURATION_MEDIUM_SHORT = 30
    DURATION_MEDIUM = 120
    DURATION_LONG = 300
    DURATION_VERY_LONG = 600
    DURATION_EXTRA_LONG = 1800
    DURATION_HOUR = 3600
    
    # å¸§ç‡åˆ†ç±»é˜ˆå€¼
    FPS_LOW = 15
    FPS_STANDARD = 30
    FPS_HIGH = 60
    
    # å¸§ç‡ä¿®æ­£å› å­
    FPS_FACTOR_LOW = 0.8
    FPS_FACTOR_STANDARD_HIGH = 1.15
    FPS_FACTOR_HIGH = 1.3
    
    # è´¨é‡è¯„åˆ†æƒé‡
    QUALITY_WEIGHT_SHARPNESS = 0.5
    QUALITY_WEIGHT_CONTRAST = 0.3
    QUALITY_WEIGHT_BRIGHTNESS = 0.2
    
    # åœºæ™¯æ£€æµ‹é˜ˆå€¼é…ç½®
    SCENE_THRESHOLDS = {
        'low': {
            'pixel_threshold': 40.0,
            'histogram_threshold': 1000.0,
            'structural_threshold': 15.0,
            'edge_threshold': 25.0,
            'color_threshold': 800.0
        },
        'medium': {
            'pixel_threshold': 25.0,
            'histogram_threshold': 500.0,
            'structural_threshold': 10.0,
            'edge_threshold': 15.0,
            'color_threshold': 400.0
        },
        'high': {
            'pixel_threshold': 15.0,
            'histogram_threshold': 200.0,
            'structural_threshold': 8.0,
            'edge_threshold': 10.0,
            'color_threshold': 200.0
        },
        'ultra': {
            'pixel_threshold': 10.0,
            'histogram_threshold': 100.0,
            'structural_threshold': 5.0,
            'edge_threshold': 8.0,
            'color_threshold': 100.0
        }
    }
    
    # å˜åŒ–å¼ºåº¦é˜ˆå€¼
    INTENSITY_THRESHOLDS = {
        'low': 15.0,
        'medium': 25.0,
        'high': 40.0,
        'ultra': 60.0
    }
    
    # å…¶ä»–é…ç½®
    MIN_FRAME_COUNT = 5
    MAX_FRAME_PERCENTAGE = 0.5
    MEMORY_CLEANUP_INTERVAL = 1000
    COMPARE_FRAME_SIZE = (160, 90)
    
    # æ–‡ä»¶å¤§å°å•ä½
    BYTES_TO_KB = 1024
    BYTES_TO_MB = 1024 * 1024

# =============================================================================
# å¼‚æ­¥è¿›åº¦ç›‘æ§
# =============================================================================

class AsyncProgressMonitor:
    """å¼‚æ­¥è¿›åº¦ç›‘æ§å™¨"""
    
    def __init__(self, total_files: int, update_interval: float = 0.5):
        self.total_files = total_files
        self.completed_files = 0
        self.current_file = ""
        self.current_progress = 0.0
        self.start_time = time.time()
        self.update_interval = update_interval
        self.callbacks = []
        self._lock = threading.Lock()
    
    def add_callback(self, callback: Callable[[Dict[str, any]], Awaitable[None]]):
        """æ·»åŠ è¿›åº¦å›è°ƒå‡½æ•°"""
        self.callbacks.append(callback)
    
    async def update_file_progress(self, filename: str, progress: float):
        """æ›´æ–°å½“å‰æ–‡ä»¶è¿›åº¦"""
        with self._lock:
            self.current_file = filename
            self.current_progress = progress
        await self._notify_callbacks()
    
    async def complete_file(self, filename: str):
        """å®Œæˆä¸€ä¸ªæ–‡ä»¶"""
        with self._lock:
            self.completed_files += 1
            self.current_file = filename
            self.current_progress = 100.0
        await self._notify_callbacks()
    
    async def _notify_callbacks(self):
        """é€šçŸ¥æ‰€æœ‰å›è°ƒå‡½æ•°"""
        if not self.callbacks:
            return
        
        progress_data = self.get_progress_data()
        
        # å¼‚æ­¥æ‰§è¡Œæ‰€æœ‰å›è°ƒ
        tasks = []
        for callback in self.callbacks:
            tasks.append(asyncio.create_task(callback(progress_data)))
        
        if tasks:
            await asyncio.gather(*tasks, return_exceptions=True)
    
    def get_progress_data(self) -> Dict[str, any]:
        """è·å–è¿›åº¦æ•°æ®"""
        elapsed_time = time.time() - self.start_time
        overall_progress = (self.completed_files / self.total_files * 100) if self.total_files > 0 else 0
        
        return {
            'total_files': self.total_files,
            'completed_files': self.completed_files,
            'current_file': self.current_file,
            'current_file_progress': self.current_progress,
            'overall_progress': overall_progress,
            'elapsed_time': elapsed_time,
            'estimated_remaining': self._estimate_remaining_time(elapsed_time, overall_progress)
        }
    
    def _estimate_remaining_time(self, elapsed: float, progress: float) -> float:
        """ä¼°ç®—å‰©ä½™æ—¶é—´"""
        if progress <= 0:
            return 0
        total_estimated = elapsed * 100 / progress
        return max(0, total_estimated - elapsed)

# =============================================================================
# å¼‚æ­¥æŠ½å¸§å™¨ä¸»ç±»
# =============================================================================

class AsyncFrameExtractor:
    """å¼‚æ­¥è§†é¢‘æŠ½å¸§å™¨"""
    
    def __init__(self, output_dir: str = None, max_file_size_mb: int = None, 
                 auto_detect_performance: bool = True):
        """åˆå§‹åŒ–å¼‚æ­¥æŠ½å¸§å™¨"""
        self.output_dir = output_dir or AsyncFrameExtractorConfig.DEFAULT_OUTPUT_DIR
        self.max_file_size_mb = max_file_size_mb or AsyncFrameExtractorConfig.DEFAULT_MAX_FILE_SIZE_MB
        self.max_file_size_bytes = self.max_file_size_mb * AsyncFrameExtractorConfig.BYTES_TO_MB
        
        os.makedirs(self.output_dir, exist_ok=True)
        
        # æ‰€æœ‰æ”¯æŒçš„æ ¼å¼
        self.supported_formats = (AsyncFrameExtractorConfig.SUPPORTED_VIDEO_FORMATS | 
                                 AsyncFrameExtractorConfig.SUPPORTED_IMAGE_FORMATS)
        
        # è®¾å¤‡æ€§èƒ½æ£€æµ‹
        self.performance_detector = DevicePerformanceDetector()
        if auto_detect_performance:
            self.performance_profile = self.performance_detector.get_performance_profile()
        else:
            self.performance_profile = self.performance_detector._get_default_profile()
        
        # çº¿ç¨‹æ± å’Œèµ„æºç®¡ç†
        self.thread_pool = None
        self.semaphore = None
        self._setup_resources()
        
        logger.info(f"âœ“ å¼‚æ­¥æŠ½å¸§å™¨åˆå§‹åŒ–å®Œæˆ - è¾“å‡ºç›®å½•: {self.output_dir}")
        logger.info(f"ğŸ”§ æ€§èƒ½é…ç½®: {self.performance_profile['performance_level']} | "
                   f"æœ€å¤§å·¥ä½œçº¿ç¨‹: {self.performance_profile['max_workers']} | "
                   f"æ‰¹å¤„ç†å¤§å°: {self.performance_profile['recommended_batch_size']}")
    
    def _setup_resources(self):
        """è®¾ç½®èµ„æºç®¡ç†"""
        config = self.performance_profile['concurrency_config']
        
        # åˆ›å»ºçº¿ç¨‹æ± 
        self.thread_pool = concurrent.futures.ThreadPoolExecutor(
            max_workers=config['max_workers'],
            thread_name_prefix="FrameExtractor"
        )
        
        # åˆ›å»ºä¿¡å·é‡é™åˆ¶å¹¶å‘
        self.semaphore = asyncio.Semaphore(config['batch_size'])
    
    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        await self.cleanup()
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.thread_pool:
            self.thread_pool.shutdown(wait=True)
            self.thread_pool = None
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()
        logger.info("ğŸ§¹ èµ„æºæ¸…ç†å®Œæˆ")
    
    def generate_task_id(self, device_id: str) -> str:
        """ç”Ÿæˆä»»åŠ¡ID"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
        return f"{timestamp}_{device_id}"
    
    def create_task_output_dir(self, task_id: str) -> str:
        """åˆ›å»ºä»»åŠ¡è¾“å‡ºç›®å½•"""
        task_output_dir = os.path.join(self.output_dir, task_id)
        os.makedirs(task_output_dir, exist_ok=True)
        return task_output_dir
    
    async def validate_file(self, file_path: str) -> Dict[str, any]:
        """å¼‚æ­¥æ–‡ä»¶éªŒè¯"""
        def _sync_validate():
            result = {'valid': False, 'error': None, 'file_info': {}}
            
            try:
                # åŸºç¡€æ£€æŸ¥
                if not os.path.exists(file_path):
                    result['error'] = f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
                    return result
                
                file_ext = os.path.splitext(file_path)[1].lower()
                if file_ext not in self.supported_formats:
                    result['error'] = f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}"
                    return result
                
                file_size = os.path.getsize(file_path)
                if file_size > self.max_file_size_bytes:
                    result['error'] = f"æ–‡ä»¶è¿‡å¤§: {file_size/AsyncFrameExtractorConfig.BYTES_TO_MB:.1f}MB"
                    return result
                
                # åˆ¤æ–­æ–‡ä»¶ç±»å‹å¹¶è·å–ä¿¡æ¯
                if file_ext in AsyncFrameExtractorConfig.SUPPORTED_VIDEO_FORMATS:
                    return self._validate_video_sync(file_path, file_size, file_ext)
                else:
                    return self._validate_image_sync(file_path, file_size, file_ext)
                    
            except Exception as e:
                result['error'] = f"éªŒè¯å‡ºé”™: {str(e)}"
                return result
        
        # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥éªŒè¯
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(self.thread_pool, _sync_validate)
    
    def _validate_video_sync(self, file_path: str, file_size: int, file_ext: str) -> Dict[str, any]:
        """åŒæ­¥éªŒè¯è§†é¢‘æ–‡ä»¶"""
        result = {'valid': False, 'error': None, 'file_info': {}}
        
        cap = cv2.VideoCapture(file_path)
        if not cap.isOpened():
            result['error'] = "æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶"
            return result
        
        try:
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            
            if total_frames <= 0 or fps <= 0 or width <= 0 or height <= 0:
                result['error'] = "è§†é¢‘å‚æ•°å¼‚å¸¸"
                return result
            
            result['valid'] = True
            result['file_info'] = {
                'file_path': file_path,
                'file_name': os.path.basename(file_path),
                'file_size_mb': file_size / AsyncFrameExtractorConfig.BYTES_TO_MB,
                'file_extension': file_ext,
                'file_type': 'video',
                'total_frames': total_frames,
                'fps': fps,
                'width': width,
                'height': height,
                'duration_seconds': total_frames / fps,
                'resolution': f"{width}x{height}"
            }
            
        finally:
            cap.release()
            
        return result
    
    def _validate_image_sync(self, file_path: str, file_size: int, file_ext: str) -> Dict[str, any]:
        """åŒæ­¥éªŒè¯å›¾ç‰‡æ–‡ä»¶"""
        result = {'valid': False, 'error': None, 'file_info': {}}
        
        image = cv2.imread(file_path)
        if image is None:
            result['error'] = "æ— æ³•è¯»å–å›¾ç‰‡æ–‡ä»¶"
            return result
        
        height, width = image.shape[:2]
        channels = image.shape[2] if len(image.shape) == 3 else 1
        
        if width <= 0 or height <= 0:
            result['error'] = "å›¾ç‰‡å°ºå¯¸å¼‚å¸¸"
            return result
        
        result['valid'] = True
        result['file_info'] = {
            'file_path': file_path,
            'file_name': os.path.basename(file_path),
            'file_size_mb': file_size / AsyncFrameExtractorConfig.BYTES_TO_MB,
            'file_extension': file_ext,
            'file_type': 'image',
            'width': width,
            'height': height,
            'channels': channels,
            'resolution': f"{width}x{height}"
        }
        
        return result
    
    def calculate_optimal_frame_count(self, duration: float, fps: float, total_frames: int) -> Dict[str, any]:
        """ä¼˜åŒ–çš„æŠ½å¸§æ•°é‡è®¡ç®—ï¼ˆåŒæ­¥æ–¹æ³•ï¼‰"""
        # æ ¹æ®æ—¶é•¿ç¡®å®šé—´éš”å’Œç­–ç•¥
        if duration <= AsyncFrameExtractorConfig.DURATION_ULTRA_SHORT:
            interval = AsyncFrameExtractorConfig.INTERVAL_ULTRA_SHORT
            strategy = "æçŸ­è§†é¢‘è¶…å¯†é›†é‡‡æ ·"
        elif duration <= AsyncFrameExtractorConfig.DURATION_SHORT:
            interval = AsyncFrameExtractorConfig.INTERVAL_SHORT
            strategy = "çŸ­è§†é¢‘å¯†é›†é‡‡æ ·"
        elif duration <= AsyncFrameExtractorConfig.DURATION_MEDIUM_SHORT:
            interval = AsyncFrameExtractorConfig.INTERVAL_MEDIUM_SHORT
            strategy = "ä¸­çŸ­è§†é¢‘å¯†é›†é‡‡æ ·"
        elif duration <= AsyncFrameExtractorConfig.DURATION_MEDIUM:
            interval = AsyncFrameExtractorConfig.INTERVAL_MEDIUM
            strategy = "ä¸­ç­‰è§†é¢‘æ ‡å‡†é‡‡æ ·"
        elif duration <= AsyncFrameExtractorConfig.DURATION_LONG:
            interval = AsyncFrameExtractorConfig.INTERVAL_LONG
            strategy = "é•¿è§†é¢‘å¯†é›†é‡‡æ ·"
        elif duration <= AsyncFrameExtractorConfig.DURATION_VERY_LONG:
            interval = AsyncFrameExtractorConfig.INTERVAL_VERY_LONG
            strategy = "è¶…é•¿è§†é¢‘é‡‡æ ·"
        elif duration <= AsyncFrameExtractorConfig.DURATION_EXTRA_LONG:
            interval = AsyncFrameExtractorConfig.INTERVAL_EXTRA_LONG
            strategy = "30åˆ†é’Ÿè§†é¢‘é‡‡æ ·"
        elif duration <= AsyncFrameExtractorConfig.DURATION_HOUR:
            interval = AsyncFrameExtractorConfig.INTERVAL_HOUR
            strategy = "1å°æ—¶è§†é¢‘é‡‡æ ·"
        else:
            interval = AsyncFrameExtractorConfig.INTERVAL_SUPER_LONG
            strategy = "è¶…é•¿è§†é¢‘é‡‡æ ·"
        
        optimal_frames = max(AsyncFrameExtractorConfig.MIN_FRAME_COUNT, int(duration / interval))
        
        # å¸§ç‡ä¿®æ­£
        fps_factor = 1.0
        if fps < AsyncFrameExtractorConfig.FPS_LOW:
            fps_factor = AsyncFrameExtractorConfig.FPS_FACTOR_LOW
        elif fps > AsyncFrameExtractorConfig.FPS_HIGH:
            fps_factor = AsyncFrameExtractorConfig.FPS_FACTOR_HIGH
        elif fps > AsyncFrameExtractorConfig.FPS_STANDARD:
            fps_factor = AsyncFrameExtractorConfig.FPS_FACTOR_STANDARD_HIGH
        
        optimal_frames = int(optimal_frames * fps_factor)
        
        # æ€»å¸§æ•°é™åˆ¶
        max_allowed = min(total_frames, int(total_frames * AsyncFrameExtractorConfig.MAX_FRAME_PERCENTAGE))
        optimal_frames = min(optimal_frames, max_allowed)
        
        frame_interval = max(1, total_frames // optimal_frames)
        real_interval = duration / optimal_frames if optimal_frames > 0 else interval
        
        return {
            'optimal_frames': optimal_frames,
            'frame_interval': frame_interval,
            'real_time_interval': real_interval,
            'strategy': strategy
        }
    
    def calculate_frame_quality(self, frame: np.ndarray) -> Dict[str, float]:
        """è®¡ç®—å¸§è´¨é‡æŒ‡æ ‡ï¼ˆåŒæ­¥æ–¹æ³•ï¼‰"""
        # è½¬æ¢ä¸ºç°åº¦å›¾
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) if len(frame.shape) == 3 else frame
        
        # æ¸…æ™°åº¦ï¼ˆæ‹‰æ™®æ‹‰æ–¯æ–¹å·®ï¼‰
        sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()
        
        # äº®åº¦å’Œå¯¹æ¯”åº¦
        brightness = np.mean(gray)
        contrast = np.std(gray)
        
        # ç»¼åˆè´¨é‡åˆ†
        quality_score = (
            sharpness * AsyncFrameExtractorConfig.QUALITY_WEIGHT_SHARPNESS +
            contrast * AsyncFrameExtractorConfig.QUALITY_WEIGHT_CONTRAST +
            min(brightness / 128.0, 1.0) * AsyncFrameExtractorConfig.QUALITY_WEIGHT_BRIGHTNESS
        )
        
        return {
            'sharpness': sharpness,
            'brightness': brightness,
            'contrast': contrast,
            'quality_score': quality_score
        }
    
    def detect_scene_change(self, frame1: np.ndarray, frame2: np.ndarray, 
                          sensitivity: str = 'high') -> Dict[str, any]:
        """ç®€åŒ–çš„åœºæ™¯å˜åŒ–æ£€æµ‹ï¼ˆåŒæ­¥æ–¹æ³•ï¼‰"""
        # è½¬æ¢ä¸ºç°åº¦å›¾å¹¶ç¡®ä¿å°ºå¯¸ä¸€è‡´
        gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY) if len(frame1.shape) == 3 else frame1
        gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY) if len(frame2.shape) == 3 else frame2
        
        if gray1.shape != gray2.shape:
            gray2 = cv2.resize(gray2, (gray1.shape[1], gray1.shape[0]))
        
        # è®¡ç®—åƒç´ å·®å¼‚
        pixel_diff = np.mean(cv2.absdiff(gray1, gray2))
        
        # è®¡ç®—ç›´æ–¹å›¾å·®å¼‚
        hist1 = cv2.calcHist([gray1], [0], None, [256], [0, 256])
        hist2 = cv2.calcHist([gray2], [0], None, [256], [0, 256])
        hist_diff = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CHISQR)
        
        # è·å–é˜ˆå€¼
        thresholds = AsyncFrameExtractorConfig.SCENE_THRESHOLDS.get(sensitivity, 
                                                             AsyncFrameExtractorConfig.SCENE_THRESHOLDS['high'])
        
        # åˆ¤æ–­åœºæ™¯å˜åŒ–
        pixel_change = pixel_diff > thresholds['pixel_threshold']
        hist_change = hist_diff > thresholds['histogram_threshold']
        
        # ç»¼åˆåˆ¤æ–­
        is_scene_change = pixel_change or hist_change
        
        # è®¡ç®—å˜åŒ–å¼ºåº¦
        change_intensity = (
            pixel_diff / thresholds['pixel_threshold'] * 0.6 +
            hist_diff / thresholds['histogram_threshold'] * 0.4
        )
        
        return {
            'is_scene_change': is_scene_change,
            'change_intensity': change_intensity,
            'pixel_difference': pixel_diff,
            'histogram_difference': hist_diff
        }
    
    def resize_frame(self, frame: np.ndarray, max_resolution: tuple) -> np.ndarray:
        """è°ƒæ•´å¸§åˆ†è¾¨ç‡ï¼ˆåŒæ­¥æ–¹æ³•ï¼‰"""
        if max_resolution is None:
            return frame
            
        height, width = frame.shape[:2]
        max_width, max_height = max_resolution
        
        scale = min(max_width / width, max_height / height, 1.0)
        
        if scale < 1.0:
            new_width = int(width * scale)
            new_height = int(height * scale)
            frame = cv2.resize(frame, (new_width, new_height), interpolation=cv2.INTER_AREA)
        
        return frame
    
    async def extract_frames_async(self, video_path: str, progress_monitor: AsyncProgressMonitor = None, **kwargs) -> Dict[str, any]:
        """å¼‚æ­¥è§†é¢‘æŠ½å¸§æ–¹æ³•"""
        async with self.semaphore:  # é™åˆ¶å¹¶å‘
            logger.info(f"ğŸ¬ å¼€å§‹å¼‚æ­¥æŠ½å¸§: {os.path.basename(video_path)}")
            start_time = time.time()
            
            # è·å–å‚æ•°
            quality = kwargs.get('quality', AsyncFrameExtractorConfig.DEFAULT_QUALITY)
            max_resolution = kwargs.get('max_resolution')
            sharpness_threshold = kwargs.get('sharpness_threshold', AsyncFrameExtractorConfig.DEFAULT_SHARPNESS_THRESHOLD)
            similarity_threshold = kwargs.get('similarity_threshold', AsyncFrameExtractorConfig.DEFAULT_SIMILARITY_THRESHOLD)
            scene_sensitivity = kwargs.get('scene_sensitivity', AsyncFrameExtractorConfig.DEFAULT_SCENE_SENSITIVITY)
            max_base_frames = kwargs.get('max_base_frames', AsyncFrameExtractorConfig.DEFAULT_MAX_BASE_FRAMES)
            
            # éªŒè¯æ–‡ä»¶
            validation = await self.validate_file(video_path)
            if not validation['valid']:
                return {'success': False, 'error': validation['error']}
            
            video_info = validation['file_info']
            if video_info['file_type'] != 'video':
                return {'success': False, 'error': 'ä¸æ˜¯è§†é¢‘æ–‡ä»¶'}
            
            # è®¡ç®—æŠ½å¸§å‚æ•°
            calc_result = self.calculate_optimal_frame_count(
                video_info['duration_seconds'], 
                video_info['fps'], 
                video_info['total_frames']
            )
            
            # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œå®é™…çš„å¸§æå–
            def _extract_frames():
                return self._extract_frames_sync(
                    video_path, video_info, calc_result, quality, max_resolution,
                    sharpness_threshold, similarity_threshold, scene_sensitivity,
                    max_base_frames, progress_monitor
                )
            
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(self.thread_pool, _extract_frames)
            
            processing_time = time.time() - start_time
            
            if result['success']:
                logger.info(f"âœ… å¼‚æ­¥æŠ½å¸§å®Œæˆ: {len(result['frame_paths'])} å¸§, è€—æ—¶ {processing_time:.2f}ç§’")
                result['processing_time'] = processing_time
                result['calculation_result'] = calc_result
            
            return result
    
    def _extract_frames_sync(self, video_path: str, video_info: Dict, calc_result: Dict,
                           quality: int, max_resolution: tuple, sharpness_threshold: float,
                           similarity_threshold: float, scene_sensitivity: str,
                           max_base_frames: int, progress_monitor: AsyncProgressMonitor = None) -> Dict[str, any]:
        """åŒæ­¥å¸§æå–æ ¸å¿ƒé€»è¾‘"""
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            return {'success': False, 'error': 'æ— æ³•æ‰“å¼€è§†é¢‘'}
        
        try:
            frame_paths = []
            frame_count = 0
            extracted_count = 0
            previous_frame = None
            last_progress_update = 0
            
            jpeg_params = [cv2.IMWRITE_JPEG_QUALITY, quality]
            frame_interval = calc_result['frame_interval']
            total_frames = video_info['total_frames']
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # æ›´æ–°è¿›åº¦
                if progress_monitor and time.time() - last_progress_update > AsyncFrameExtractorConfig.PROGRESS_UPDATE_INTERVAL:
                    progress = (frame_count / total_frames) * 100
                    # æ³¨æ„ï¼šè¿™é‡Œä¸èƒ½ç›´æ¥è°ƒç”¨å¼‚æ­¥æ–¹æ³•ï¼Œéœ€è¦åœ¨å¤–å±‚å¤„ç†
                    last_progress_update = time.time()
                
                # å‡åŒ€æŠ½å¸§
                if frame_count % frame_interval == 0:
                    # è°ƒæ•´åˆ†è¾¨ç‡
                    processed_frame = self.resize_frame(frame, max_resolution)
                    
                    # è´¨é‡è¯„ä¼°
                    quality_metrics = self.calculate_frame_quality(processed_frame)
                    
                    # åˆ¤æ–­æ˜¯å¦ä¿ç•™
                    should_keep = self._should_keep_frame(
                        processed_frame, previous_frame, quality_metrics,
                        sharpness_threshold, similarity_threshold, scene_sensitivity
                    )
                    
                    if should_keep:
                        # ä¿å­˜å¸§
                        timestamp = frame_count / video_info['fps']
                        filename = f"frame_{extracted_count:04d}_{timestamp:.2f}s.jpg"
                        filepath = os.path.join(self.output_dir, filename)
                        
                        if cv2.imwrite(filepath, processed_frame, jpeg_params):
                            frame_info = {
                                'path': filepath,
                                'filename': filename,
                                'frame_number': frame_count,
                                'timestamp': timestamp,
                                'extracted_index': extracted_count,
                                'quality_metrics': quality_metrics,
                                'source_type': 'video',
                                'source_file': os.path.basename(video_path)
                            }
                            frame_paths.append(frame_info)
                            
                            # æ›´æ–°å‰ä¸€å¸§ç”¨äºæ¯”è¾ƒ
                            previous_frame = cv2.resize(processed_frame, AsyncFrameExtractorConfig.COMPARE_FRAME_SIZE)
                            extracted_count += 1
                            
                            # è¾¾åˆ°æœ€å¤§å¸§æ•°åˆ™é€€å‡º
                            if extracted_count >= max_base_frames:
                                break
                
                frame_count += 1
                
                # å®šæœŸå†…å­˜æ£€æŸ¥
                if frame_count % AsyncFrameExtractorConfig.MEMORY_CHECK_INTERVAL == 0:
                    memory_percent = psutil.virtual_memory().percent
                    if memory_percent > AsyncFrameExtractorConfig.MAX_MEMORY_USAGE_PERCENT:
                        logger.warning(f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ ({memory_percent:.1f}%), æ‰§è¡Œåƒåœ¾å›æ”¶")
                        gc.collect()
        
        finally:
            cap.release()
        
        return {
            'success': True,
            'video_info': video_info,
            'frame_paths': frame_paths
        }
    
    def _should_keep_frame(self, frame: np.ndarray, previous_frame: Optional[np.ndarray], 
                          quality_metrics: Dict[str, float], sharpness_threshold: float,
                          similarity_threshold: float, scene_sensitivity: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¿ç•™å¸§ï¼ˆåŒæ­¥æ–¹æ³•ï¼‰"""
        # ç¬¬ä¸€å¸§æ€»æ˜¯ä¿ç•™
        if previous_frame is None:
            return True
        
        # æ¸…æ™°åº¦æ£€æŸ¥
        if quality_metrics['sharpness'] < sharpness_threshold:
            return False
        
        # åœºæ™¯å˜åŒ–æ£€æµ‹
        scene_result = self.detect_scene_change(previous_frame, frame, scene_sensitivity)
        
        # å¦‚æœå‘ç”Ÿåœºæ™¯å˜åŒ–ï¼Œæ£€æŸ¥å˜åŒ–å¼ºåº¦
        if scene_result['is_scene_change']:
            intensity_threshold = AsyncFrameExtractorConfig.INTENSITY_THRESHOLDS.get(scene_sensitivity, 40.0)
            return scene_result['change_intensity'] >= intensity_threshold
        
        # å¦‚æœæ²¡æœ‰åœºæ™¯å˜åŒ–ï¼Œæ£€æŸ¥åƒç´ å·®å¼‚
        return scene_result['pixel_difference'] >= similarity_threshold
    
    async def process_image_file_async(self, image_path: str, **kwargs) -> Dict[str, any]:
        """å¼‚æ­¥å¤„ç†å›¾ç‰‡æ–‡ä»¶"""
        async with self.semaphore:  # é™åˆ¶å¹¶å‘
            def _process_image():
                quality = kwargs.get('quality', AsyncFrameExtractorConfig.DEFAULT_QUALITY)
                max_resolution = kwargs.get('max_resolution')
                
                # è¯»å–å’Œå¤„ç†å›¾ç‰‡
                image = cv2.imread(image_path)
                if image is None:
                    return {'success': False, 'error': 'æ— æ³•è¯»å–å›¾ç‰‡æ–‡ä»¶'}
                
                processed_image = self.resize_frame(image, max_resolution)
                quality_metrics = self.calculate_frame_quality(processed_image)
                
                # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
                base_name = os.path.splitext(os.path.basename(image_path))[0]
                output_filename = f"image_{base_name}.jpg"
                output_path = os.path.join(self.output_dir, output_filename)
                
                # ä¿å­˜å›¾ç‰‡
                jpeg_params = [cv2.IMWRITE_JPEG_QUALITY, quality]
                if cv2.imwrite(output_path, processed_image, jpeg_params):
                    return {
                        'success': True,
                        'file_type': 'image',
                        'output_info': {
                            'path': output_path,
                            'filename': output_filename,
                            'quality_metrics': quality_metrics
                        }
                    }
                else:
                    return {'success': False, 'error': 'ä¿å­˜å›¾ç‰‡å¤±è´¥'}
            
            # éªŒè¯å›¾ç‰‡
            validation = await self.validate_file(image_path)
            if not validation['valid']:
                return {'success': False, 'error': validation['error']}
            
            file_info = validation['file_info']
            if file_info['file_type'] != 'image':
                return {'success': False, 'error': 'ä¸æ˜¯å›¾ç‰‡æ–‡ä»¶'}
            
            # åœ¨çº¿ç¨‹æ± ä¸­å¤„ç†å›¾ç‰‡
            loop = asyncio.get_event_loop()
            return await loop.run_in_executor(self.thread_pool, _process_image)
    
    async def process_multiple_files_async(self, input_paths: List[str], device_id: str = None, 
                                         task_id: str = None, progress_callback: Callable = None,
                                         **kwargs) -> Dict[str, any]:
        """å¼‚æ­¥å¤„ç†å¤šä¸ªæ–‡ä»¶ï¼ˆæ ¸å¿ƒå¹¶è¡Œå¤„ç†æ–¹æ³•ï¼‰"""
        # å¤„ç†ä»»åŠ¡ID
        if task_id is None:
            device_id = device_id or "async_device"
            task_id = self.generate_task_id(device_id)
        
        # åˆ›å»ºä»»åŠ¡ç›®å½•
        task_output_dir = self.create_task_output_dir(task_id)
        original_output_dir = self.output_dir
        self.output_dir = task_output_dir
        
        # è®¾ç½®è¿›åº¦ç›‘æ§
        progress_monitor = AsyncProgressMonitor(len(input_paths))
        if progress_callback:
            progress_monitor.add_callback(progress_callback)
        
        logger.info(f"ğŸš€ å¼€å§‹å¼‚æ­¥å¹¶è¡Œå¤„ç† {len(input_paths)} ä¸ªæ–‡ä»¶ - ä»»åŠ¡ID: {task_id}")
        logger.info(f"âš™ï¸ å¹¶è¡Œé…ç½®: æœ€å¤§å·¥ä½œçº¿ç¨‹ {self.performance_profile['max_workers']}, "
                   f"æ‰¹å¤„ç†å¤§å° {self.performance_profile['recommended_batch_size']}")
        
        start_time = time.time()
        
        try:
            all_frame_paths = []
            success_count = 0
            failed_count = 0
            
            # åˆ›å»ºå¤„ç†ä»»åŠ¡
            async def process_single_file(file_path: str) -> Tuple[str, Dict[str, any]]:
                """å¤„ç†å•ä¸ªæ–‡ä»¶çš„å¼‚æ­¥åŒ…è£…"""
                try:
                    await progress_monitor.update_file_progress(os.path.basename(file_path), 0)
                    
                    validation = await self.validate_file(file_path)
                    if not validation['valid']:
                        await progress_monitor.complete_file(os.path.basename(file_path))
                        return file_path, {'success': False, 'error': validation['error']}
                    
                    if validation['file_info']['file_type'] == 'video':
                        result = await self.extract_frames_async(file_path, progress_monitor, **kwargs)
                    else:
                        result = await self.process_image_file_async(file_path, **kwargs)
                    
                    await progress_monitor.complete_file(os.path.basename(file_path))
                    return file_path, result
                    
                except Exception as e:
                    logger.error(f"å¤„ç†æ–‡ä»¶å¼‚å¸¸ {file_path}: {str(e)}")
                    await progress_monitor.complete_file(os.path.basename(file_path))
                    return file_path, {'success': False, 'error': str(e)}
            
            # å¹¶è¡Œå¤„ç†æ‰€æœ‰æ–‡ä»¶
            batch_size = self.performance_profile['recommended_batch_size']
            
            for i in range(0, len(input_paths), batch_size):
                batch = input_paths[i:i + batch_size]
                
                # åˆ›å»ºå½“å‰æ‰¹æ¬¡çš„ä»»åŠ¡
                tasks = [process_single_file(file_path) for file_path in batch]
                
                # ç­‰å¾…å½“å‰æ‰¹æ¬¡å®Œæˆ
                results = await asyncio.gather(*tasks, return_exceptions=True)
                
                # å¤„ç†ç»“æœ
                for file_path, result in results:
                    if isinstance(result, Exception):
                        logger.error(f"å¤„ç†æ–‡ä»¶å¼‚å¸¸ {file_path}: {str(result)}")
                        failed_count += 1
                        continue
                    
                    if result['success']:
                        success_count += 1
                        if 'frame_paths' in result:
                            all_frame_paths.extend(result['frame_paths'])
                        elif 'output_info' in result:
                            # è½¬æ¢å›¾ç‰‡ç»“æœä¸ºå¸§æ ¼å¼
                            frame_info = {
                                'path': result['output_info']['path'],
                                'filename': result['output_info']['filename'],
                                'frame_number': 0,
                                'timestamp': 0.0,
                                'extracted_index': len(all_frame_paths),
                                'quality_metrics': result['output_info']['quality_metrics'],
                                'source_type': 'image',
                                'source_file': os.path.basename(file_path)
                            }
                            all_frame_paths.append(frame_info)
                    else:
                        failed_count += 1
                
                # æ‰¹æ¬¡é—´çš„çŸ­æš‚ä¼‘æ¯ï¼Œå…è®¸ç³»ç»Ÿå›æ”¶èµ„æº
                if i + batch_size < len(input_paths):
                    await asyncio.sleep(0.1)
                    gc.collect()
            
            # å¦‚æœè¶…è¿‡æœ€å¤§å¸§æ•°é™åˆ¶ï¼ŒæŒ‰è´¨é‡æ’åºä¿ç•™
            max_base_frames = kwargs.get('max_base_frames', AsyncFrameExtractorConfig.DEFAULT_MAX_BASE_FRAMES)
            if len(all_frame_paths) > max_base_frames:
                all_frame_paths.sort(key=lambda x: x['quality_metrics']['quality_score'], reverse=True)
                
                # åˆ é™¤å¤šä½™æ–‡ä»¶
                for frame_info in all_frame_paths[max_base_frames:]:
                    try:
                        if os.path.exists(frame_info['path']):
                            os.remove(frame_info['path'])
                    except:
                        pass
                
                all_frame_paths = all_frame_paths[:max_base_frames]
            
            # é‡æ–°å‘½åæ–‡ä»¶ç¡®ä¿é¡ºåº
            await self._rename_frames_async(all_frame_paths)
            
            processing_time = time.time() - start_time
            
            logger.info(f"âœ… å¼‚æ­¥å¹¶è¡Œå¤„ç†å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {failed_count}, è€—æ—¶ {processing_time:.2f}ç§’")
            
            return {
                'success': success_count > 0,
                'task_id': task_id,
                'device_id': device_id,
                'task_output_dir': task_output_dir,
                'total_files': len(input_paths),
                'success_count': success_count,
                'failed_count': failed_count,
                'frame_paths': all_frame_paths,
                'batch_processing_time': processing_time,
                'performance_profile': self.performance_profile
            }
            
        finally:
            self.output_dir = original_output_dir
    
    async def _rename_frames_async(self, all_frame_paths: List[Dict]):
        """å¼‚æ­¥é‡æ–°å‘½åå¸§æ–‡ä»¶"""
        def _rename_files():
            for i, frame_info in enumerate(all_frame_paths):
                old_path = frame_info['path']
                clean_name = os.path.splitext(frame_info['source_file'])[0]
                new_filename = f"frame_{i:04d}_{frame_info['source_type']}_{clean_name}.jpg"
                new_path = os.path.join(self.output_dir, new_filename)
                
                try:
                    if old_path != new_path and os.path.exists(old_path):
                        if os.path.exists(new_path):
                            os.remove(new_path)
                        os.rename(old_path, new_path)
                        frame_info['path'] = new_path
                        frame_info['filename'] = new_filename
                        frame_info['extracted_index'] = i
                except Exception as e:
                    logger.warning(f"é‡å‘½åæ–‡ä»¶å¤±è´¥ {old_path}: {e}")
        
        # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œæ–‡ä»¶é‡å‘½å
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(self.thread_pool, _rename_files)
    
    def format_output(self, processing_result: Dict[str, any], save_json: bool = True) -> Dict[str, any]:
        """æ ¼å¼åŒ–è¾“å‡ºç»“æœï¼ˆåŒæ­¥æ–¹æ³•ï¼‰"""
        if not processing_result.get('success', False):
            return {
                'success': False,
                'error': processing_result.get('error', 'å¤„ç†å¤±è´¥'),
                'device_id': processing_result.get('device_id'),
                'task_id': processing_result.get('task_id'),
                'base_frame_paths': []
            }
        
        # æ„å»ºåŸºç¡€å¸§è·¯å¾„æ•°ç»„
        base_frame_paths = []
        for frame_info in processing_result.get('frame_paths', []):
            frame_data = {
                'file_path': frame_info['path'],
                'filename': frame_info['filename'],
                'source_type': frame_info.get('source_type', 'unknown'),
                'source_file': frame_info.get('source_file', 'unknown'),
                'extracted_index': frame_info.get('extracted_index', 0),
                'timestamp': frame_info.get('timestamp', 0.0),
                'quality_metrics': {
                    'sharpness': round(frame_info['quality_metrics']['sharpness'], 2),
                    'brightness': round(frame_info['quality_metrics']['brightness'], 2),
                    'contrast': round(frame_info['quality_metrics']['contrast'], 2),
                    'quality_score': round(frame_info['quality_metrics']['quality_score'], 2)
                }
            }
            base_frame_paths.append(frame_data)
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        total_size_mb = sum(os.path.getsize(f['path']) for f in processing_result['frame_paths'] 
                           if os.path.exists(f['path'])) / AsyncFrameExtractorConfig.BYTES_TO_MB
        
        formatted_result = {
            'success': True,
            'device_id': processing_result.get('device_id', 'unknown'),
            'task_id': processing_result.get('task_id', 'unknown'),
            'base_frame_paths': base_frame_paths,
            'processing_summary': {
                'total_input_files': processing_result.get('total_files', 0),
                'success_files': processing_result.get('success_count', 0),
                'failed_files': processing_result.get('failed_count', 0),
                'final_frame_count': len(base_frame_paths),
                'processing_time_seconds': round(processing_result.get('batch_processing_time', 0), 2),
                'performance_profile': processing_result.get('performance_profile', {})
            },
            'storage_info': {
                'task_output_directory': processing_result.get('task_output_dir', ''),
                'total_size_mb': round(total_size_mb, 2),
                'frame_format': 'JPEG'
            },
            'metadata': {
                'extraction_timestamp': datetime.now().isoformat(),
                'extractor_version': '3.0.0-async',
                'async_processing': True,
                'parallel_batches': True
            }
        }
        
        # ä¿å­˜JSONç»“æœ
        if save_json:
            json_path = self._save_json_result(formatted_result)
            if json_path:
                formatted_result['storage_info']['json_result_path'] = json_path
        
        return formatted_result
    
    def _save_json_result(self, formatted_result: Dict[str, any]) -> Optional[str]:
        """ä¿å­˜JSONç»“æœï¼ˆåŒæ­¥æ–¹æ³•ï¼‰"""
        try:
            task_output_dir = formatted_result['storage_info']['task_output_directory']
            task_id = formatted_result['task_id']
            
            json_filename = f"async_frames_result_{task_id}.json"
            json_path = os.path.join(task_output_dir, json_filename)
            
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(formatted_result, f, ensure_ascii=False, indent=2, default=str)
            
            return json_path
        except Exception as e:
            logger.error(f"ä¿å­˜JSONå¤±è´¥: {str(e)}")
            return None
    
    async def process_and_format_async(self, input_paths: List[str], device_id: str = None, 
                                     task_id: str = None, save_json: bool = True, 
                                     progress_callback: Callable = None, **kwargs) -> Dict[str, any]:
        """ä¸€é”®å¼‚æ­¥å¤„ç†å¹¶æ ¼å¼åŒ–è¾“å‡º"""
        try:
            # å¤„ç†å¤šä¸ªæ–‡ä»¶
            processing_result = await self.process_multiple_files_async(
                input_paths, device_id, task_id, progress_callback, **kwargs
            )
            
            # æ ¼å¼åŒ–è¾“å‡º
            formatted_output = self.format_output(processing_result, save_json)
            
            if formatted_output['success']:
                logger.info(f"âœ… ä¸€é”®å¼‚æ­¥å¤„ç†å®Œæˆ: {len(formatted_output['base_frame_paths'])} å¸§")
            
            return formatted_output
            
        except Exception as e:
            logger.error(f"ä¸€é”®å¼‚æ­¥å¤„ç†å¼‚å¸¸: {str(e)}")
            return {
                'success': False,
                'error': f"å¤„ç†å¼‚å¸¸: {str(e)}",
                'device_id': device_id,
                'task_id': task_id,
                'base_frame_paths': []
            }

# =============================================================================
# ç¤ºä¾‹å’Œæµ‹è¯•
# =============================================================================

async def example_progress_callback(progress_data: Dict[str, any]):
    """ç¤ºä¾‹è¿›åº¦å›è°ƒå‡½æ•°"""
    print(f"ğŸ“Š å¤„ç†è¿›åº¦: {progress_data['overall_progress']:.1f}% | "
          f"å½“å‰æ–‡ä»¶: {progress_data['current_file']} ({progress_data['current_file_progress']:.1f}%) | "
          f"å·²å®Œæˆ: {progress_data['completed_files']}/{progress_data['total_files']} | "
          f"é¢„è®¡å‰©ä½™: {progress_data['estimated_remaining']:.1f}ç§’")

async def main():
    """å¼‚æ­¥ç¤ºä¾‹ç”¨æ³•"""
    print("=== å¼‚æ­¥å¹¶è¡Œæ™ºèƒ½è§†é¢‘æŠ½å¸§ç³»ç»Ÿ ===\n")
    
    # ä½¿ç”¨å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    async with AsyncFrameExtractor(output_dir="async_frames") as extractor:
        
        # æŸ¥æ‰¾æµ‹è¯•æ–‡ä»¶
        test_files = []
        for filename in os.listdir('.'):
            file_ext = os.path.splitext(filename)[1].lower()
            if file_ext in extractor.supported_formats:
                test_files.append(filename)
        
        if not test_files:
            print("âŒ æœªæ‰¾åˆ°æµ‹è¯•æ–‡ä»¶")
            return
        
        print(f"ğŸ“ å‘ç° {len(test_files)} ä¸ªæ–‡ä»¶")
        print(f"ğŸ”§ è®¾å¤‡æ€§èƒ½: {extractor.performance_profile['performance_level']}")
        print(f"âš™ï¸ å¹¶è¡Œé…ç½®: æœ€å¤§å·¥ä½œçº¿ç¨‹ {extractor.performance_profile['max_workers']}, "
              f"æ‰¹å¤„ç†å¤§å° {extractor.performance_profile['recommended_batch_size']}\n")
        
        # æµ‹è¯•å¼‚æ­¥ä¸€é”®å¤„ç†
        device_id = "async_test_device_001"
        result = await extractor.process_and_format_async(
            input_paths=test_files,
            device_id=device_id,
            quality=90,
            max_resolution=(1920, 1080),
            scene_sensitivity='high',
            progress_callback=example_progress_callback
        )
        
        if result['success']:
            print(f"\nâœ… å¼‚æ­¥å¤„ç†æˆåŠŸ:")
            print(f"  ä»»åŠ¡ID: {result['task_id']}")
            print(f"  åŸºç¡€å¸§æ•°: {len(result['base_frame_paths'])}")
            print(f"  å¤„ç†æ—¶é—´: {result['processing_summary']['processing_time_seconds']}ç§’")
            print(f"  æ€§èƒ½ç­‰çº§: {result['processing_summary']['performance_profile']['performance_level']}")
            print(f"  æˆåŠŸæ–‡ä»¶: {result['processing_summary']['success_files']}")
            print(f"  å¤±è´¥æ–‡ä»¶: {result['processing_summary']['failed_files']}")
        else:
            print(f"âŒ å¼‚æ­¥å¤„ç†å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

if __name__ == '__main__':
    # è¿è¡Œå¼‚æ­¥ä¸»å‡½æ•°
    asyncio.run(main())